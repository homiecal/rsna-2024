{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-22T10:31:28.333461Z","iopub.status.busy":"2024-10-22T10:31:28.332987Z","iopub.status.idle":"2024-10-22T10:31:28.342108Z","shell.execute_reply":"2024-10-22T10:31:28.340718Z","shell.execute_reply.started":"2024-10-22T10:31:28.333425Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import cv2\n","import pydicom\n","import numpy as np\n","import os\n","import glob\n","from tqdm import tqdm\n","import warnings\n","import pandas as pd\n","DATA_PATH = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/'\n","WORKING_DIR = '/kaggle/input/rsna-2024-train/'\n","DATASET_SELECTION = 'sagittal'\n","SET_TYPE='test'\n","train_candidates = pd.read_csv(WORKING_DIR+'train_candidates.csv')\n","train_candidates.head(5)\n","train_candidates[train_candidates['study_id']==1085426528].groupby(['series_id','series_description']).size()\n","from collections import namedtuple\n","import functools\n","import datetime\n","from torch.utils.data import Dataset\n","import random\n","import pickle\n","from torch import tensor\n","\n","SEVERITY_MAPPING = {\"Normal/Mild\":0,\"Moderate\":1,\"Severe\":2}\n","SEVERITY_WEIGHTING = {0:1.0,1:2.0,2:4.0}\n","severity_candidate_dict = {'44036939_2828203845_left_neural_foraminal_narrowing_l4_l5': \n","                        {'instance_no': [22,23],\n","                          'box_coord': [tensor([186.6035, 251.5714,  40.5323,  36.3092]),\n","                           tensor([185.6549, 252.8904,  41.1806,  36.0747])],\n","                          'box_conf': [tensor(0.5057), tensor(0.3758)],\n","                          'roi_xyxy': (253, 316, 358, 415),\n","                          'conf_xyxy': (255, 316, 358, 413),\n","                          'conf_instance_no': 22,\n","                         # TODO add these attributes in\n","                         'img_path':f\"{DATA_PATH}/{SET_TYPE}_images/44036939/2828203845/22.dcm\",\n","                         'study_id':\"44036939\",\n","                         'series_id':\"2828203845\",\n","                         \"set_type\":\"Sagittal T1\"\n","                        }\n","                       }\n","severity_candidate_list = [{**value,**{\"row_id\":key}} for key, value in severity_candidate_dict.items()]\n","severity_candidate_list"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset\n","\n","Classification Component Set:\n","- candidate_list: list of instances with bounding box coordinates *(need to adjust for image boundaries)* \n","- sorted_study_ids: the list of study_ids sorted with respect to condition severity, used for creating robust validation sets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-22T10:31:30.019789Z","iopub.status.busy":"2024-10-22T10:31:30.019403Z","iopub.status.idle":"2024-10-22T10:31:30.778802Z","shell.execute_reply":"2024-10-22T10:31:30.777759Z","shell.execute_reply.started":"2024-10-22T10:31:30.019761Z"},"trusted":true},"outputs":[],"source":["# Initialise candidate_info_tuple\n","candidate_info_tuple = namedtuple(\n","    'candidate_info_tuple',\n","    'row_id, study_id, series_id, instance_number, has_centres, centre_xy, severity, img_path, width_bbox, height_bbox'\n",")\n","\n","# Read in relevant Classification Component Set\n","with open(f'/kaggle/input/rsna-2024-train-candidate-list/candidate_list_{DATASET_SELECTION}.pkl', 'rb') as f:\n","    out = pickle.load(f)\n","    \n","candidate_list, sorted_study_ids = out['candidate_list'],out['sorted_study_ids'] \n","@functools.lru_cache(1, typed=True)\n","def get_image(path):\n","    return pydicom.dcmread(path)\n","# Pass img_path which is mutable and can be easily cached, get_image() is also cached\n","# and so this should not result in additional compute\n","@functools.lru_cache(1, typed=True)\n","def get_roi(img_path, x_centre, y_centre, width = 50, height = 40):\n","    image = get_image(img_path)\n","    y_max, x_max = image.pixel_array.shape\n","    x_left, x_right, y_bot, y_top = int(max(0,x_centre - width//2)), int(min(x_max, x_centre + width//2)), int(max(0, y_centre - height//2)), int(min(y_max, y_centre + height//2))\n","    roi = image.pixel_array[y_bot:y_top,x_left:x_right]\n","    return roi.astype(np.uint8)\n","# Pass img_path which is mutable and can be easily cached, get_image() is also cached\n","# and so this should not result in additional compute\n","@functools.lru_cache(1, typed=True)\n","def get_roi_xyxy(img_path, x_left, x_right, y_bot, y_top):\n","    image = get_image(img_path)\n","    roi = image.pixel_array[y_bot:y_top,x_left:x_right]\n","    return roi.astype(np.uint8)"]},{"cell_type":"markdown","metadata":{},"source":["### Plot images"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-22T10:31:30.812266Z","iopub.status.busy":"2024-10-22T10:31:30.811825Z","iopub.status.idle":"2024-10-22T10:31:30.822074Z","shell.execute_reply":"2024-10-22T10:31:30.821014Z","shell.execute_reply.started":"2024-10-22T10:31:30.812224Z"},"trusted":true},"outputs":[],"source":["def dicom_transforms(img: np.array):\n","    IMG_normalized = cv2.normalize(img, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n","    # Convert the image from BGR to RGB for correct color display in matplotlib\n","    IMG_normalized = cv2.cvtColor(IMG_normalized, cv2.COLOR_BGR2RGB)\n","    return IMG_normalized\n","import matplotlib.pyplot as plt\n","import cv2\n","import os\n","import glob\n","import math\n","import re\n","\n","# Function to extract the numeric values from the filename\n","def extract_numbers(file_path):\n","    filename = file_path.split('/')[-1]\n","    numbers = re.findall(r'\\d+', filename)\n","    return list(map(int, numbers))\n","\n","\n","def plot_images(image_dir,pattern=\"*\"):\n","    \"\"\"\n","    Plot YOLO predictions and ground truth labels on images.\n","\n","    Parameters:\n","    - image_dir (str): Directory containing the images.\n","    - label_dir (str): Directory containing the label files.\n","    - model: YOLO model for making predictions.\n","    - pattern (str): Pattern to match image files in the directory.\n","    \"\"\"\n","    # Get list of images\n","    image_paths = sorted(glob.glob(os.path.join(image_dir, pattern)),key=extract_numbers)\n","    \n","    # Plot image with ground truth and predicted boxes\n","    num_rows = math.ceil(len(image_paths)/4)\n","    fig, ax = plt.subplots(num_rows, 4, figsize=(12, 12))      \n","    \n","    if num_rows > 1:\n","        ax = ax.flatten()\n","    else:\n","        ax = [ax]  # Make it iterable for consistency    \n","    \n","    imgs = []\n","    for i, image_path in enumerate(image_paths):\n","        # Load image\n","        img = get_image(image_path)\n","        imgs.append(img)\n","        IMG = img.pixel_array\n","        IMG_normalized = cv2.normalize(IMG, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n","        # Convert the image from BGR to RGB for correct color display in matplotlib\n","        IMG_normalized = cv2.cvtColor(IMG_normalized, cv2.COLOR_BGR2RGB)\n","        \n","        ax[i].imshow(IMG_normalized)\n","        \n","    # Show the result\n","    plt.show()\n","        \n","    return imgs\n","        \n","# Example usage:\n","out = plot_images(image_dir=\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images/\",\n","           pattern=\"1085426528/1518511736/*\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-22T10:31:33.713658Z","iopub.status.busy":"2024-10-22T10:31:33.713184Z","iopub.status.idle":"2024-10-22T10:31:33.743874Z","shell.execute_reply":"2024-10-22T10:31:33.742587Z","shell.execute_reply.started":"2024-10-22T10:31:33.713621Z"},"trusted":true},"outputs":[],"source":["class InferenceLumbarSeverityDataset(Dataset):\n","    \n","    def __init__(self,\n","                val_stride=0,\n","                val_set=False,\n","                study_id=None,\n","                candidate_list=None,\n","                transform=None,\n","                sample: int | None = None,\n","                rand_bbox: bool = False,\n","                sorted_candidate_list=None, \n","                save_to_drive: bool = False,\n","                debug_mode: bool = False):\n","        \n","        self.sample = sample\n","        self.rand_bbox = rand_bbox\n","        self.save_to_drive = save_to_drive\n","        self.debug_mode = debug_mode\n","        self.val_set = val_set\n","        \n","        if candidate_list:\n","            self.candidate_list = candidate_list\n","        else:\n","            raise Exception(\"Must provide candidate_list.\")\n","        \n","        # Default to a stratified sampled of candidates by study_id (option to provide custom sorted list on other\n","        # stratifications).\n","        if sorted_candidate_list:\n","            self.sorted_candidate_list = sorted_candidate_list.copy()\n","        else:\n","            study_ids = np.unique([x['study_id'] for x in self.candidate_list])\n","            self.sorted_candidate_list = np.random.shuffle(study_ids)        \n","\n","        if study_id:\n","            self.candidate_list = [x for x in self.candidate_list if x['study_id'] == study_id]\n","        \n","        if self.val_set:\n","            assert val_stride > 0, val_stride\n","            val_study_ids = self.sorted_candidate_list[::val_stride]\n","            self.candidate_list = [x for x in self.candidate_list if str(x['study_id']) in val_study_ids]\n","            assert self.candidate_list\n","        elif val_stride > 0:\n","            del self.sorted_candidate_list[::val_stride]                        \n","            self.candidate_list = [x for x in self.candidate_list if str(x['study_id']) in self.sorted_candidate_list]            \n","            assert self.candidate_list\n","    \n","        self.transform = transform\n","    \n","    def __len__(self):\n","        if self.sample:\n","            return min(self.sample, len(self.candidate_list))\n","        else:\n","            return len(self.candidate_list)\n","    \n","    def __getitem__(self,ndx):\n","        \"\"\"\n","        return \n","        \"\"\"\n","        \n","        candidate = self.candidate_list[ndx]\n","        \n","        if self.rand_bbox:    \n","            width = randint(40,60)\n","            height = randint(50,70)\n","            candidate = self.candidate_list[ndx].udpate({'width_bbox':width, 'height_bbox':height})\n","            self.candidate_list[ndx] = candidate\n","\n","        roi = get_roi_xyxy(candidate['img_path'], *candidate['conf_xyxy']) # TODO unpack a tuple in a function\n","    \n","        if self.transform:\n","            try:\n","                roi = self.transform(roi)        \n","            except Exception as e:\n","                print(f\"Exception raised for {candidate.row_id} \\n\\n {e}\")                \n","        \n","        return roi, candidate['row_id'], candidate\n","        \n","    def get_items_by_study(self, study_id):\n","        \"\"\"\n","        Get items for a specific study.\n","        \"\"\"\n","        study_candidates = [i for i, x in enumerate(self.candidate_list) if x.study_id == study_id]\n","        result = [self.__getitem__(i) for i in study_candidates]\n","\n","        return result        \n","\n","    def get_items_by_row_id(self, row_id, debug=False):\n","        \"\"\"\n","        Get items for a specific study.\n","        \"\"\"\n","        study_candidates = [i for i, x in enumerate(self.candidate_list) if x.row_id == row_id]\n","        if debug:\n","            try:\n","                result = [self.__getitem__(i) for i in study_candidates]\n","            except Exception:\n","                return get_roi_xyxy(candidate.img_path, *candidate.conf_xyxy), candidate\n","        else:\n","            result = [self.__getitem__(i) for i in study_candidates]\n","\n","        return result     \n","dataset = InferenceLumbarSeverityDataset(candidate_list=severity_candidate_list)\n","# for i in range(len(dataset)):\n","#     roi, sev, row_id = dataset[i]\n","#     x, y = roi.shape\n","    \n","#     if x <= 0 or y <= 0:\n","#         print(row_id)\n","dataset[0]"]},{"cell_type":"markdown","metadata":{},"source":["### Model and Config"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-22T10:31:34.212807Z","iopub.status.busy":"2024-10-22T10:31:34.211815Z","iopub.status.idle":"2024-10-22T10:31:34.220371Z","shell.execute_reply":"2024-10-22T10:31:34.218868Z","shell.execute_reply.started":"2024-10-22T10:31:34.212756Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch import nn\n","from PIL import Image\n","from torchvision import models\n","from torchvision.transforms import transforms\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision.transforms import v2\n","import torch.nn.functional as F\n","import timm\n","\n","class Config:\n","    def __init__(self):\n","        # Training parameters\n","        self.batch_size = 32\n","        self.learning_rate = 5e-4\n","        self.num_epochs = 20\n","        self.trained_epochs = None\n","        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","        \n","        # Dataset\n","        self.roi_width_range = (40,60)\n","        self.roi_height_range = (50,70)\n","        \n","        # Model parameters\n","        self.model_type = 'resnet50.a1_in1k'\n","        self.pretrained = True\n","        self.num_classes = 3\n","        self.fc = 'fc'\n","        self.trainable_layers = ['layer4']\n","        \n","        # Optimization parameters\n","        self.optimizer = 'adam'\n","        self.weight_decay = 1e-4\n","        self.momentum = 0.9\n","        \n","        # Scheduler parameters\n","        self.use_scheduler = True\n","        self.scheduler = 'cosine_annealing'\n","        self.T_max = 50\n","        \n","        # Early stopping\n","        self.early_stop = True\n","        self.early_stop_patience = 5\n","        \n","        # Mixed precision training\n","        self.use_amp = True\n","        self.clip_grad = True\n","        self.clip_value = 1.0\n","        \n","        # Augmentation\n","        self.horizontal_flip = 0.5\n","        self.random_affine = True\n","        \n","        # Logging parameters\n","        self.log_interval = 10\n","        self.tensorboard_log_dir = './logs'\n","        \n","    def update(self, **kwargs):\n","        \"\"\" Update configuration parameters. \"\"\"\n","        for key, value in kwargs.items():\n","            if hasattr(self, key):\n","                setattr(self, key, value)\n","            else:\n","                raise AttributeError(f\"{key} is not a valid attribute of Config\")\n","        return self  # Return the entire Config object\n","                \n","    def get(self,value: str, default: any = Ellipsis):\n","        if hasattr(self,value):\n","            return getattr(self,value)\n","        else:\n","            if default is Ellipsis:\n","                raise ValueError(f\"Attribute '{value}' does not exist and no default value was provided.\")\n","            return default\n","\n","\n","# Example usage\n","config = Config()\n","\n","# # Update parameters if needed\n","# config.update(batch_size=64, learning_rate=0.0005, num_epochs=100)\n","\n","# Example model definition (same as before)\n","class LumbarNet(nn.Module):\n","    def __init__(self, config: dict):\n","        super(LumbarNet, self).__init__()\n","        \n","        self.config = config\n","        \n","        pretrained = config.get(\"pretrained\")\n","        model_type = config.get(\"model_type\")\n","        self.model = timm.create_model(model_type,pretrained) # keep linear head for in_features\n","\n","        # Set trainable layers\n","        trainable_layers = config.get('trainable_layers',[])        \n","        if trainable_layers:\n","            self.set_layer_requires_grad(trainable_layers)\n","        else:\n","            self.freeze_all(self.model)\n","\n","        # Set fully connected\n","        fc = config.get('fc',None)\n","        if fc:\n","            out = getattr(self.model, fc)\n","            in_f = out.in_features\n","            new_fc = nn.Linear(in_f, config.get('num_classes'))\n","            setattr(self.model, fc, new_fc)\n","        \n","    def forward(self, x):\n","        return self.model(x)\n","    \n","    @staticmethod\n","    def freeze_all(model):\n","        for param in model.parameters():\n","            param.requires_grad = False\n","            \n","    def set_layer_requires_grad(self, layers_to_unfreeze):\n","        # Freeze all layers first\n","        self.freeze_all(self.model)\n","\n","        # Unfreeze the specified layers\n","        for layer_name in layers_to_unfreeze:\n","            layer = getattr(self.model, layer_name, None)\n","            if layer and not isinstance(layer, nn.BatchNorm2d):\n","                for param in layer.parameters():\n","                    param.requires_grad = True\n","class ToRGB(object):\n","    def __call__(self, img):\n","        if isinstance(img, np.ndarray):\n","            # Convert NumPy array to PIL Image\n","            img = Image.fromarray(img)\n","        # Convert the image to RGB mode\n","        img_rgb = img.convert('RGB')\n","        return img_rgb\n","def get_standard_transforms(model: nn.Module):\n","    \"\"\"\n","    Only applied if pretrained=True.\n","    \n","    Removes CentreCrop which is likely to hinder performance when ROI are small enough anyway.\n","    \"\"\"\n","    data_config = timm.data.resolve_model_data_config(model)\n","    transform_list = timm.data.create_transform(**data_config, is_training=False)\n","\n","    filtered_transforms = [t for t in transform_list.transforms if not isinstance(t, transforms.CenterCrop)]\n","\n","    return filtered_transforms\n","def get_transforms(config: dict, model: nn.Module):\n","    \n","    transforms_list = []\n","    \n","    inference_transforms =  [ToRGB(),\n","             transforms.Resize(size=(256,256), interpolation=transforms.InterpolationMode.BICUBIC, max_size=None),\n","             transforms.ToTensor(),\n","             transforms.Normalize(mean=torch.tensor([0.4850, 0.4560, 0.4060]), std=torch.tensor([0.2290, 0.2240, 0.2250]))]\n","        \n","    if config.get(\"pretrained\",False):\n","\n","        transforms_list.extend(inference_transforms)\n","        \n","    else:\n","        # TODO standard minmax transforms to dataset\n","        transforms_list.append(ToRGB())\n","\n","\n","    if config.get(\"horizontal_flip\", False):\n","        transforms_list.append(v2.RandomHorizontalFlip(p=config.get(\"horizontal_flip\")))\n","    \n","    if config.get(\"random_affine\", False):\n","        transforms_list.append(v2.RandomApply([\n","                v2.RandomAffine(\n","                    degrees=(-20, 20), translate=(0.0,0.25), scale=(0.75, 1)\n","                )],p=0.25))\n","            \n","            \n","    composed_transforms = transforms.Compose(transforms_list)\n","    \n","    return composed_transforms, transforms.Compose(inference_transforms)"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluation"]},{"cell_type":"code","execution_count":111,"metadata":{"execution":{"iopub.execute_input":"2024-10-22T10:31:37.179815Z","iopub.status.busy":"2024-10-22T10:31:37.179421Z","iopub.status.idle":"2024-10-22T10:31:37.189222Z","shell.execute_reply":"2024-10-22T10:31:37.187864Z","shell.execute_reply.started":"2024-10-22T10:31:37.179784Z"},"trusted":true},"outputs":[],"source":["def inference(model, loader, device):\n","    \n","    labels = {}\n","    results = []\n","    probs_list = {}\n","    with torch.no_grad():\n","        for batch in loader:\n","            inputs, row_ids, candidates = batch\n","            inputs = inputs.to(device)\n","            outputs = model(inputs)\n","            \n","            probs = F.softmax(outputs, dim=1)\n","            \n","            results.append(zip(row_ids,probs.cpu()))\n","            \n","            labels = labels | {row_id: np.argmax(x.numpy()) for row_id, x in zip(row_ids, outputs.cpu())}\n","            probs_list = probs_list | {row_id: prob.numpy() for row_id, prob in zip(row_ids, probs.cpu())}\n","            \n","    return results, labels, probs_list     "]},{"cell_type":"markdown","metadata":{},"source":["#### Inference script"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-22T10:31:38.153738Z","iopub.status.busy":"2024-10-22T10:31:38.153288Z","iopub.status.idle":"2024-10-22T10:31:38.974859Z","shell.execute_reply":"2024-10-22T10:31:38.973588Z","shell.execute_reply.started":"2024-10-22T10:31:38.153706Z"},"trusted":true},"outputs":[],"source":["import pickle\n","import timm\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","best_model_state = torch.load(\"/kaggle/input/severity-classification/pytorch/resnet-sagittal-t1/1/resnet50.a1_in1k_2024-089_13-24-01_earlystop.pth\",\n","                             map_location = device)\n","config = Config()\n","model = LumbarNet(config)\n","model.load_state_dict(best_model_state['model'])\n","model = model.to(device)\n","\n","_, transform = get_transforms(config,model)\n","\n","# Create dataset\n","dataset = InferenceLumbarSeverityDataset(candidate_list=severity_candidate_list,\n","                                         transform=transform)\n","\n","data_loader = DataLoader(dataset, batch_size=16)\n","\n","results, labels, probs_list = inference(model, data_loader, device)\n","probs_list\n","for x in severity_candidate_list:\n","    probs = probs_list[x['row_id']]\n","    severity = labels[x['row_id']]\n","    \n","    x.update({\"probs_x\":probs})\n","    x.update({\"severity\":severity})    \n","results = pd.DataFrame(severity_candidate_list)\n","results.groupby('severity').size()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":8561470,"sourceId":71549,"sourceType":"competition"},{"datasetId":5245104,"sourceId":8737101,"sourceType":"datasetVersion"},{"datasetId":5428119,"sourceId":9194304,"sourceType":"datasetVersion"},{"modelId":101872,"modelInstanceId":77229,"sourceId":92122,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
